import os
import sys
sys.path.append('../../cloud-detection-code')
sys.path.append('../../cloud-detection-code/scripts')
from scripts.c8_invariant_cnn import C8InvariantCNN, DenseC8InvariantCNN
from scripts.block_builder import InvariantType
from scripts.train_pytorch_model import save_model_at_checkpoint, load_model_from_checkpoint 
from scripts.luminosity_classifier import LuminosityClassifier
from scripts.random_forest_classifier import RandomForest 
from scripts.evaluate_model import ClassifierValidator
import torch
import torchvision.transforms.functional as F
from torchvision.transforms import ToTensor
from PIL import Image
import matplotlib.pyplot as plt

def load_model_for_eval(model_name, epoch, lr, verbose=False, input_channels=4):
    """
    This function loads a model from a checkpoint.

    Arguments
    ----------
        model_name: string
            name of the subdirectory to load the model from
        epoch: int
            epoch number of the model
        lr: float
            learning rate of the model
        verbose: bool (optional)
            if True, print out the model name

    Returns
    --------
        model_loaded: torch.nn.Module
            loaded PyTorch model to test
    """
    if verbose:
        print("Loading model {}".format(model_name))
    current_dir = os.path.dirname(os.path.abspath(__file__))

    if 'lum' in model_name:
        model_loaded = LuminosityClassifier(None)
        model_paths = os.listdir(os.path.join(current_dir, 'saved_models', model_name))
        model_paths = [f for f in model_paths if 'pkl' in f]
        model_path = os.path.join(current_dir, 'saved_models', model_name, model_paths[0])
        model_loaded.load_thresholds(model_path)
        if ('swir' not in model_name and 'rgb' not in model_name) or 'lwir' in model_name:
            model_loaded.reverse_keys = (3,)
        else:
            model_loaded.reverse_keys = ()
        model_loaded = model_loaded.classify
    elif 'rf' in model_name:
        model_loaded = RandomForest(None)
        model_paths = os.listdir(os.path.join(current_dir, 'saved_models', model_name))
        model_paths = [f for f in model_paths if 'pkl' in f]
        model_path = os.path.join(current_dir, 'saved_models', model_name, model_paths[0])

        model_loaded.load_classifier(model_path)
        model_loaded = model_loaded.classify
    else:
        device = 'cuda' if torch.cuda.is_available() else 'cpu'

        #Load model from checkpoint
        dir_path = os.path.join(current_dir, 'saved_models', model_name)
        if 'NONE' in model_name:
            if 'nondense' in model_name:
                model_loaded = C8InvariantCNN(input_channels=input_channels, inv_group_type=InvariantType.NONE).to(device)
            else:
                model_loaded = DenseC8InvariantCNN(input_channels=input_channels, inv_group_type=InvariantType.NONE).to(device)
        elif 'nondense' in model_name:
            model_loaded = C8InvariantCNN(input_channels=input_channels).to(device)
        else:
            model_loaded = DenseC8InvariantCNN(input_channels=input_channels).to(device)
        opt_loaded = torch.optim.Adam
        if 'road' in model_name:
            opt_loaded = torch.optim.SGD
        model_loaded, opt_loaded, epoch_loaded, train_err_loaded = load_model_from_checkpoint(model_loaded, opt_loaded, epoch, lr, dir_path)

    return model_loaded 

def plot_model_comparison(img, lum_mask, rf_mask, unet_mask, dense_mask, rot_unet_mask, rot_dense_mask, buffer_save_name, rgb_only=False, unets_only=False):
    """
    Plot masks generated by different models against each other.
    """
    if rgb_only:
        if unets_only:
            shape=(2,6)
            figshape = (12, 8)
        else:
            shape = (2,8)
            figshape = (12, 6)
        plt.figure(figsize=figshape, dpi=80)
        ax_rgb = plt.subplot2grid(shape=shape, loc=(0,0), colspan=2)
        ax_truth = plt.subplot2grid(shape, (0,2), colspan=2)
        if not unets_only:
            ax_lum = plt.subplot2grid(shape, (0,4), colspan=2)
            ax_rf = plt.subplot2grid(shape, (0,6), colspan=2)
            ax_unet = plt.subplot2grid(shape, (1,0), colspan=2)
            ax_dense_unet = plt.subplot2grid(shape, (1,2), colspan=2)
            ax_rot_unet = plt.subplot2grid(shape, (1,4), colspan=2)
            ax_rot_dense_unet = plt.subplot2grid(shape, (1, 6), colspan=2)

            truth_label, lum_label, rf_label = '(b)', '(c)', '(d)'
            unet_label, dense_unet_label = '(e)', '(f)'
            rot_unet_label, rot_dense_unet_label = '(g)', '(h)'
        else:
            ax_unet = plt.subplot2grid(shape, (0, 4), colspan=2)
            ax_dense_unet = plt.subplot2grid(shape, (1,0), colspan=2)
            ax_rot_unet = plt.subplot2grid(shape, (1,2), colspan=2)
            ax_rot_dense_unet = plt.subplot2grid(shape, (1, 4), colspan=2)

            truth_label  = '(b)'
            unet_label, dense_unet_label = '(c)', '(d)'
            rot_unet_label, rot_dense_unet_label = '(e)', '(f)'
    else:
        if unets_only:
            raise ValueError("Can't have unets only and LWIR/SWIR")
        plt.figure(figsize=(12, 10), dpi=80)
        ax_rgb = plt.subplot2grid(shape=(3,8), loc=(0,0), colspan=2)
        ax_lwir = plt.subplot2grid((3,8), (0,2), colspan=2)
        ax_swir = plt.subplot2grid((3,8), (0,4), colspan=2)
        ax_truth = plt.subplot2grid((3,8), (0,6), colspan=2)
        ax_lum = plt.subplot2grid((3,8), (1,1), colspan=2)
        ax_rf = plt.subplot2grid((3,8), (1,3), colspan=2)
        ax_unet = plt.subplot2grid((3,8), (1,5), colspan=2)
        ax_dense_unet = plt.subplot2grid((3,8), (2,1), colspan=2)
        ax_rot_unet = plt.subplot2grid((3,8), (2,3), colspan=2)
        ax_rot_dense_unet = plt.subplot2grid((3,8), (2,5), colspan=2)

        truth_label, lum_label, rf_label = '(d)', '(e)', '(f)'
        unet_label, dense_unet_label = '(g)', '(h)'
        rot_unet_label, rot_dense_unet_label = '(i)', '(j)'

    plt.subplots_adjust(hspace=0.5, wspace=1)

    ax_rgb.set_title('(a)')# RGB image')
    ax_rgb.imshow(img['img'][0:3, :, :].permute(1, 2, 0).cpu().numpy())
    if not rgb_only:
        ax_lwir.set_title('(b)')# LWIR image')
        ax_lwir.imshow(img['img'][3, :, :].cpu().numpy())
        ax_swir.set_title('(c)')# SWIR image')
        ax_swir.imshow(img['img'][4, :, :].cpu().numpy())
    ax_truth.set_title(truth_label)#Ref mask
    ax_truth.imshow(img['ref'][0, :, :].cpu().numpy(), vmin=0, vmax=1)
    if not unets_only:
        ax_lum.set_title(lum_label)#Luminosity
        ax_lum.imshow(lum_mask[0, 0, :, :].detach().numpy(), vmin=0, vmax=1)
        ax_rf.set_title(rf_label)#Random forest
        ax_rf.imshow(rf_mask[0, 0, :, :].detach().numpy(), vmin=0, vmax=1)
    ax_unet.set_title(unet_label)#U-net 
    ax_unet.imshow(unet_mask[0, 0, :, :].detach().numpy(), vmin=0, vmax=1)
    ax_dense_unet.set_title(dense_unet_label)#Dense u-net 
    ax_dense_unet.imshow(dense_mask[0, 0, :, :].detach().numpy(), vmin=0, vmax=1)
    ax_rot_unet.set_title(rot_unet_label)#Rot inv u-net
    ax_rot_unet.imshow(rot_unet_mask[0, 0, :, :].detach().numpy(), vmin=0, vmax=1)
    ax_rot_dense_unet.set_title(rot_dense_unet_label)#Dense rot inv u-net
    ax_rot_dense_unet.imshow(rot_dense_mask[0, 0, :, :].detach().numpy(), vmin=0, vmax=1)

    plt.savefig(buffer_save_name, bbox_inches='tight')
    #plt.show()


def plot_band_comparison(img, rgb_mask, rgb_lwir_mask, rgb_swir_mask, rgb_lwir_swir_mask, buffer_save_name):
    """
    Plot masks generated by models that consider different bands against each other.
    """
    plt.figure(figsize=(12, 6), dpi=80)
    ax1 = plt.subplot2grid(shape=(2,8), loc=(0,0), colspan=2)
    ax2 = plt.subplot2grid((2,8), (0,2), colspan=2)
    ax3 = plt.subplot2grid((2,8), (0,4), colspan=2)
    ax4 = plt.subplot2grid((2,8), (0,6), colspan=2)
    ax5 = plt.subplot2grid((2,8), (1,0), colspan=2)
    ax6 = plt.subplot2grid((2,8), (1,2), colspan=2)
    ax7 = plt.subplot2grid((2,8), (1,4), colspan=2)
    ax8 = plt.subplot2grid((2,8), (1,6), colspan=2)
    plt.subplots_adjust(hspace=0.5, wspace=1)

    ax1.set_title('(a)')# RGB image')
    ax1.imshow(img['img'][0:3, :, :].permute(1, 2, 0).cpu().numpy())
    ax2.set_title('(b)')# LWIR image')
    ax2.imshow(img['img'][3, :, :].cpu().numpy())
    ax3.set_title('(c)')# SWIR image')
    ax3.imshow(img['img'][4, :, :].cpu().numpy())
    ax4.set_title('(d)')#Ref mask
    ax4.imshow(img['ref'][0, :, :].cpu().numpy(), vmin=0, vmax=1)
    
    ax5.set_title('(e)')#RGB only
    ax5.imshow(rgb_mask[0, 0, :, :].detach().numpy(), vmin=0, vmax=1)
    ax6.set_title('(f)')#RGB+LWIR 
    ax6.imshow(rgb_lwir_mask[0, 0, :, :].detach().numpy(), vmin=0, vmax=1)
    ax7.set_title('(g)')#RGB+SWIR 
    ax7.imshow(rgb_swir_mask[0, 0, :, :].detach().numpy(), vmin=0, vmax=1)
    ax8.set_title('(h)')#RGB+LWIR+SWIR 
    ax8.imshow(rgb_lwir_swir_mask[0, 0, :, :].detach().numpy(), vmin=0, vmax=1)

    plt.savefig(buffer_save_name, bbox_inches='tight')
    #plt.show()

def evaluate_models_on_img(img, models, model_channels, img_size=144, has_ir=True):
    """
    Evaluates each model in models on an image, then returns the resulting masks.
    Model_channels specifies which channels to use for each model.
    """
    #Split img into r, g, b, lwir, swir channels
    r_img = img['img'][0, :, :].reshape((1, 1, img_size, img_size))
    g_img = img['img'][1, :, :].reshape((1, 1, img_size, img_size))
    b_img = img['img'][2, :, :].reshape((1, 1, img_size, img_size))
    channel_imgs = {'r': r_img, 'g': g_img, 'b': b_img}
    if has_ir:
        lwir_img = img['img'][3, :, :].reshape((1, 1, img_size, img_size))
        swir_img = img['img'][4, :, :].reshape((1, 1, img_size, img_size))
        channel_imgs['lwir'] = lwir_img
        channel_imgs['swir'] = swir_img

    #Evaluate models
    masks = []
    for i, model in enumerate(models):
        #Get appropriate image channels for input
        channels = model_channels[i]
        imgs = []
        for channel in channels:
            imgs.append(channel_imgs[channel])
        eval_img = torch.cat(imgs, 1)
        #Evaluate model on image
        mask = model(eval_img) >= 0.5
        masks.append(mask)
    return masks
 
def load_img_from_fname(img_path, fname):
    """
    Load image given a filename with no transformations.
    """
    convert_tensor = ToTensor()

    rgbimg_name = f"{img_path}/{fname}_rgb.tif"
    irimg_name = f"{img_path}/{fname}_lwir.tif"
    swirimg_name = f"{img_path}/{fname}_swir.tif"
    ref_name = f"{img_path}/{fname}_ref.tif"

    rgb_img = convert_tensor(Image.open(rgbimg_name))
    refmask = convert_tensor(Image.open(ref_name))
    ir_img = convert_tensor(Image.open(irimg_name))
    swir_img = convert_tensor(Image.open(swirimg_name))

    rgb_img = F.resize(rgb_img, 144, interpolation=Image.NEAREST)
    refmask = F.resize(refmask, 144, interpolation=Image.NEAREST)
    ir_img = F.resize(ir_img, 144, interpolation=Image.NEAREST)
    swir_img = F.resize(swir_img, 144, interpolation=Image.NEAREST)

    img = torch.cat((rgb_img, ir_img, swir_img), 0)
    sample = {'img': img, 'ref': refmask}
    return sample

def plot_buffer_difference(img, mask, buffer_save_name, rgb_only=False, buffer=2):
    _, _, err_mask, unbuffer_err_mask, buffered_mask, buffered_ref = ClassifierValidator.compare_to_mask_buffer(img['ref'], mask, buffer)
    plt.figure(figsize=(12, 6), dpi=80)
    if rgb_only:
        ax_rgb = plt.subplot2grid(shape=(2,6), loc=(0,1), colspan=2)
        ax_bufref = plt.subplot2grid((2,6), (0,3), colspan=2)
        ax_bufmask = plt.subplot2grid((2,6), (1,0), colspan=2)
        ax_err = plt.subplot2grid((2,6), (1,2), colspan=2)
        ax_buferr = plt.subplot2grid((2,6), (1,4), colspan=2)
        buferr_title, err_title = '(e)', '(d)'
        bufmask_title, bufref_title = '(c)', '(b)'
    else:    
        ax_rgb = plt.subplot2grid(shape=(2,8), loc=(0,1), colspan=2)
        ax_lwir = plt.subplot2grid((2,8), (0,3), colspan=2)
        ax_swir = plt.subplot2grid((2,8), (0,5), colspan=2)
        ax_buferr = plt.subplot2grid((2,8), (1,0), colspan=2)
        ax_err = plt.subplot2grid((2,8), (1,2), colspan=2)
        ax_bufmask = plt.subplot2grid((2,8), (1,4), colspan=2)
        ax_bufref = plt.subplot2grid((2,8), (1,6), colspan=2)
        buferr_title, err_title = '(d)', '(e)'
        bufmask_title, bufref_title = '(f)', '(g)'

    plt.subplots_adjust(hspace=0.5, wspace=1)

    ax_buferr.imshow(err_mask[0, 0, :, :].cpu().numpy(), vmin=-1, vmax=1)
    ax_buferr.set_title(buferr_title)# Error mask with buffer = 1')
    ax_err.imshow(unbuffer_err_mask[0, 0, :, :].cpu().numpy(), vmin=-1, vmax=1)
    ax_err.set_title(err_title)# Error mask without buffer')
    ax_rgb.imshow(img['img'][0:3, :, :].permute(1, 2, 0).cpu().numpy())
    ax_rgb.set_title('(a)')# RGB image')
    if not rgb_only:
        ax_lwir.imshow(img['img'][3, :, :].cpu().numpy())
        ax_lwir.set_title('(b)')# LWIR image')
        ax_swir.imshow(img['img'][4, :, :].cpu().numpy())
        ax_swir.set_title('(c)')# SWIR image')
    ax_bufmask.imshow(buffered_mask[0, 0, :, :].cpu().numpy(), vmin=0, vmax=1)
    ax_bufmask.set_title(bufmask_title)# Buffered mask')
    ax_bufref.imshow(buffered_ref[0, 0, :, :].cpu().numpy(), vmin=0, vmax=1)
    ax_bufref.set_title(bufref_title)# Buffered reference mask')
    #plt.show()
    plt.savefig(buffer_save_name, bbox_inches='tight')



def load_road_img_from_fname(img_path, fname, size=256):
    """
    Load image given a filename with no transformations.
    """
    convert_tensor = ToTensor()

    rgbimg_name = f"{img_path}/{fname}.png"
    name_split = fname.split('_')
    name_split.insert(3, 'mask')
    mask_fname = '_'.join(name_split)
    ref_name = f"{img_path}/{mask_fname}.png"

    rgb_img = convert_tensor(Image.open(rgbimg_name))
    refmask = convert_tensor(Image.open(ref_name))

    rgb_img = F.crop(rgb_img, 0, 0, size, size)
    refmask = F.crop(refmask, 0, 0, size, size)

    #img = torch.cat((rgb_img, ir_img, swir_img), 0)
    sample = {'img': rgb_img, 'ref': refmask}
    return sample
